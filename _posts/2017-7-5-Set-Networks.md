---
layout: post
title: Set Networks - Another tool for your toolbox
---

>*Q*: What do recent teqniques for [neural machine translation](https://arxiv.org/abs/1706.03762), [relational reasoning](https://arxiv.org/abs/1612.00222), and [learning on point-clouds](https://arxiv.org/abs/1612.00593) have in common?
>
>*A*: they all use set networks!

A deep-learningomancer's toolkit is seemingly endless. Simple spells, such as batch-normalisation and skip connections are joined by arcane magic such as  (not to mention the six hundred and sixty six different species of GAN).

Needless to say, the number of different model architectures is also collosal.
However, broadly speaking, we can divide most deep learning models into one of three categories: those designed to operate on feature vectors (*e.g.* fully connected), those designed to operate on tensor-structured data such as images, or audio (*e.g.* CNNs), and those designed to work on sequential data (*e.g.* RNNs).

While this is far from a comprehensive classification of all models (doubtless large numbers of networks exist for a whole host of different esoteric input formats, not to mention the dreaded [chimera](https://arxiv.org/abs/1706.05137)), but it does hilight one glaring ommision, namely models designed to operate on sets.



### What are set networks?


### The simple set network


### Deep set networks

#### Other layer types


### Other techniques

#### Self attention

#### Heirarchical set networks
